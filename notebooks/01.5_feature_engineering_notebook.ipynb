{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphaelRAY/airbnb-rating-ml/blob/main/notebooks/01.5_feature_engineering_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e6c949",
      "metadata": {
        "id": "54e6c949"
      },
      "source": [
        "\n",
        "# 02 - Feature Engineering Geogr√°fica para Dados Airbnb - Rio de Janeiro\n",
        "\n",
        "Este notebook demonstra o processo de enriquecimento do dataset de listings do Airbnb com features geogr√°ficas, como dist√¢ncias a pontos de interesse (POIs) e contagem de POIs pr√≥ximos. Utilizamos o arquivo `listings_processed.csv` (que √© o `airbnb_rio_clean.csv` da etapa anterior) como base e o `neighbourhoods.geojson` para contexto geogr√°fico, embora os POIs sejam baixados via OpenStreetMap (OSM) para maior granularidade.\n",
        "\n",
        "**Nota:** Para evitar timeouts em ambientes com recursos limitados, este notebook executa a feature engineering em uma **amostra** do dataset. Para processar o dataset completo, as linhas de amostragem devem ser comentadas no script `02_feature_engineering.py`.\n",
        "\n",
        "## 1. Configura√ß√£o Inicial e Carregamento de Dados\n",
        "\n",
        "Importa√ß√£o das bibliotecas necess√°rias e carregamento do dataset `listings_processed.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e443a8d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e443a8d8",
        "outputId": "858e921f-bdc6-48db-e7d8-cdd75611879f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: geopandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from osmnx) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from osmnx) (3.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.32.4)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.1.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (25.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Downloading osmnx-2.0.6-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: osmnx\n",
            "Successfully installed osmnx-2.0.6\n",
            "Diret√≥rio 'data/processed' criado.\n",
            "\n",
            "--- Carregando o dataset processado de listings ---\n",
            "Dataset carregado. Shape inicial: (41724, 40)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point, Polygon\n",
        "%pip install osmnx\n",
        "import osmnx as ox\n",
        "\n",
        "# Definir o diret√≥rio de sa√≠da\n",
        "output_dir = \"data/processed\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Diret√≥rio \\'{output_dir}\\' criado.\")\n",
        "\n",
        "print(\"\\n--- Carregando o dataset processado de listings ---\")\n",
        "# Usar o arquivo listings_processed.csv fornecido pelo usu√°rio\n",
        "df = pd.read_csv(\"https://github.com/RaphaelRAY/airbnb-rating-ml/raw/refs/heads/main/data/processed/listings_Encode.csv\")\n",
        "print(f\"Dataset carregado. Shape inicial: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c69344",
      "metadata": {
        "id": "87c69344"
      },
      "source": [
        "## 2. M√≥dulo `geo_features.py`\n",
        "\n",
        "As fun√ß√µes para baixar POIs, calcular dist√¢ncias (Haversine) e adicionar features geogr√°ficas foram encapsuladas no m√≥dulo `src/airbnb_rating/utils/geo_features.py` para melhor organiza√ß√£o e reusabilidade. Este m√≥dulo inclui otimiza√ß√µes como o uso de √≠ndices espaciais para acelerar os c√°lculos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7f8740f8",
      "metadata": {
        "id": "7f8740f8"
      },
      "outputs": [],
      "source": [
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm\n",
        "\n",
        "EARTH_RADIUS_KM = 6371\n",
        "tqdm.pandas()  # ativa barra de progresso no .apply\n",
        "\n",
        "def get_pois(city: str, geojson_path: str = None):\n",
        "    tags = {\n",
        "        \"natural\": \"beach\",\n",
        "        \"aeroway\": \"aerodrome\",\n",
        "        \"tourism\": True,\n",
        "        \"amenity\": [\"restaurant\", \"bar\", \"cafe\"],\n",
        "        \"leisure\": [\"park\"]\n",
        "    }\n",
        "    print(f\"\\nüåç Baixando POIs para {city} do OpenStreetMap...\")\n",
        "    pois = ox.features_from_place(city, tags)\n",
        "    print(f\"‚úîÔ∏è {len(pois)} pontos baixados.\\n\")\n",
        "    return pois.to_crs(\"EPSG:4326\")\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return EARTH_RADIUS_KM * c\n",
        "\n",
        "def add_geo_features(df, city=\"Rio de Janeiro, Brazil\", geojson_path: str = None):\n",
        "    print(\"üöÄ Iniciando enriquecimento geogr√°fico...\\n\")\n",
        "\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df, geometry=gpd.points_from_xy(df[\"longitude\"], df[\"latitude\"]), crs=\"EPSG:4326\"\n",
        "    )\n",
        "    pois = get_pois(city, geojson_path)\n",
        "\n",
        "    beaches = pois[pois[\"natural\"] == \"beach\"]\n",
        "    airports = pois[pois[\"aeroway\"] == \"aerodrome\"]\n",
        "    tourism = pois[pois[\"tourism\"].notna()]\n",
        "    restaurants = pois[pois[\"amenity\"].isin([\"restaurant\", \"bar\", \"cafe\"])] if \"amenity\" in pois.columns else gpd.GeoDataFrame()\n",
        "    parks = pois[pois[\"leisure\"] == \"park\"]\n",
        "\n",
        "    beaches_sindex = beaches.sindex\n",
        "    airports_sindex = airports.sindex\n",
        "    tourism_sindex = tourism.sindex\n",
        "    restaurants_sindex = restaurants.sindex\n",
        "    parks_sindex = parks.sindex\n",
        "\n",
        "    def get_poi_coords(geom):\n",
        "        if geom is None or not geom.is_valid:\n",
        "            return np.nan, np.nan\n",
        "        if geom.geom_type == 'Point':\n",
        "            return geom.y, geom.x\n",
        "        elif geom.geom_type == 'Polygon':\n",
        "            return geom.centroid.y, geom.centroid.x\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    def min_dist_optimized(point_geom, targets_gdf, targets_sindex):\n",
        "        if targets_gdf.empty:\n",
        "            return np.nan\n",
        "        possible_matches_indices = list(targets_sindex.intersection(point_geom.bounds))\n",
        "        if not possible_matches_indices:\n",
        "            return np.nan\n",
        "        min_d = np.inf\n",
        "        for idx in possible_matches_indices:\n",
        "            target_geom = targets_gdf.iloc[idx].geometry\n",
        "            target_lat, target_lon = get_poi_coords(target_geom)\n",
        "            if not np.isnan(target_lat):\n",
        "                dist = haversine(point_geom.y, point_geom.x, target_lat, target_lon)\n",
        "                if dist < min_d:\n",
        "                    min_d = dist\n",
        "        return min_d if min_d != np.inf else np.nan\n",
        "\n",
        "    print(\"üìè Calculando dist√¢ncia para praias...\")\n",
        "    gdf[\"dist_beach_km\"] = gdf.geometry.progress_apply(lambda p: min_dist_optimized(p, beaches, beaches_sindex))\n",
        "\n",
        "    print(\"‚úàÔ∏è Calculando dist√¢ncia para aeroportos...\")\n",
        "    gdf[\"dist_airport_km\"] = gdf.geometry.progress_apply(lambda p: min_dist_optimized(p, airports, airports_sindex))\n",
        "\n",
        "    print(\"üèõÔ∏è Calculando dist√¢ncia para pontos tur√≠sticos...\")\n",
        "    gdf[\"dist_touristic_km\"] = gdf.geometry.progress_apply(lambda p: min_dist_optimized(p, tourism, tourism_sindex))\n",
        "\n",
        "    def count_nearby_optimized(point_geom, targets_gdf, targets_sindex, radius_km=1):\n",
        "        if targets_gdf.empty:\n",
        "            return 0\n",
        "        count = 0\n",
        "        radius_deg = radius_km / 111.139\n",
        "        buffered_point = point_geom.buffer(radius_deg)\n",
        "        possible_matches_indices = list(targets_sindex.intersection(buffered_point.bounds))\n",
        "        for idx in possible_matches_indices:\n",
        "            target_geom = targets_gdf.iloc[idx].geometry\n",
        "            target_lat, target_lon = get_poi_coords(target_geom)\n",
        "            if not np.isnan(target_lat):\n",
        "                if haversine(point_geom.y, point_geom.x, target_lat, target_lon) <= radius_km:\n",
        "                    count += 1\n",
        "        return count\n",
        "\n",
        "    print(\"üçΩÔ∏è Contando restaurantes em 1 km...\")\n",
        "    gdf[\"n_restaurants_1km\"] = gdf.geometry.progress_apply(\n",
        "        lambda p: count_nearby_optimized(p, restaurants, restaurants_sindex, radius_km=1)\n",
        "    )\n",
        "\n",
        "    print(\"üå≥ Contando parques em 2 km...\")\n",
        "    gdf[\"n_parks_2km\"] = gdf.geometry.progress_apply(\n",
        "        lambda p: count_nearby_optimized(p, parks, parks_sindex, radius_km=2)\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ Enriquecimento conclu√≠do.\\n\")\n",
        "    return pd.DataFrame(gdf.drop(columns=\"geometry\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e68112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12e68112",
        "outputId": "0fd3e540-e1db-4456-ffd2-c25eecb92add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Adicionando features geogr√°ficas autom√°ticas ---\n",
            "üöÄ Iniciando enriquecimento geogr√°fico...\n",
            "\n",
            "\n",
            "üåç Baixando POIs para Rio de Janeiro, Brazil do OpenStreetMap...\n",
            "‚úîÔ∏è 5682 pontos baixados.\n",
            "\n",
            "üìè Calculando dist√¢ncia para praias...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41724/41724 [00:11<00:00, 3646.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úàÔ∏è Calculando dist√¢ncia para aeroportos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41724/41724 [00:01<00:00, 28308.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèõÔ∏è Calculando dist√¢ncia para pontos tur√≠sticos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41724/41724 [00:01<00:00, 28318.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üçΩÔ∏è Contando restaurantes em 1 km...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|‚ñç         | 1606/41724 [00:40<20:08, 33.20it/s]"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Adicionando features geogr√°ficas autom√°ticas ---\")\n",
        "df_enriched = add_geo_features(df, city=\"Rio de Janeiro, Brazil\") # Usar\n",
        "print(f\"Dataset enriquecido. Novo shape: {df_enriched.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101813af",
      "metadata": {
        "id": "101813af"
      },
      "source": [
        "## 4. Salvando o Dataset Enriquecido\n",
        "\n",
        "O dataset resultante, contendo as novas features geogr√°ficas, √© salvo em um novo arquivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3deac0",
      "metadata": {
        "id": "2a3deac0",
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Salvando o dataset enriquecido ---\")\n",
        "df_enriched.to_csv(os.path.join(output_dir, \"airbnb_rio_geo_sample.csv\"), index=False) # Salvar amostra\n",
        "print(\"‚úÖ Dataset enriquecido (amostra) salvo em data/processed/airbnb_rio_geo_sample.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb21eea7",
      "metadata": {
        "id": "bb21eea7"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
