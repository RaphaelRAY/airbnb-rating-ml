{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphaelRAY/airbnb-rating-ml/blob/main/notebooks/02_feature_engineering_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e6c949",
      "metadata": {
        "id": "54e6c949"
      },
      "source": [
        "\n",
        "# 02 - Feature Engineering Geográfica para Dados Airbnb - Rio de Janeiro\n",
        "\n",
        "Este notebook demonstra o processo de enriquecimento do dataset de listings do Airbnb com features geográficas, como distâncias a pontos de interesse (POIs) e contagem de POIs próximos. Utilizamos o arquivo `listings_processed.csv` (que é o `airbnb_rio_clean.csv` da etapa anterior) como base e o `neighbourhoods.geojson` para contexto geográfico, embora os POIs sejam baixados via OpenStreetMap (OSM) para maior granularidade.\n",
        "\n",
        "**Nota:** Para evitar timeouts em ambientes com recursos limitados, este notebook executa a feature engineering em uma **amostra** do dataset. Para processar o dataset completo, as linhas de amostragem devem ser comentadas no script `02_feature_engineering.py`.\n",
        "\n",
        "## 1. Configuração Inicial e Carregamento de Dados\n",
        "\n",
        "Importação das bibliotecas necessárias e carregamento do dataset `listings_processed.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e443a8d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e443a8d8",
        "outputId": "bd3fd047-5176-4708-903f-2fa24e5ed5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: geopandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from osmnx) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from osmnx) (3.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.32.4)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from osmnx) (2.1.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (25.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=1.0.1->osmnx) (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27->osmnx) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Downloading osmnx-2.0.6-py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: osmnx\n",
            "Successfully installed osmnx-2.0.6\n",
            "Diretório 'data/processed' criado.\n",
            "\n",
            "--- Carregando o dataset processado de listings ---\n",
            "Dataset carregado. Shape inicial: (38249, 65)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point, Polygon\n",
        "%pip install osmnx\n",
        "import osmnx as ox\n",
        "\n",
        "# Definir o diretório de saída\n",
        "output_dir = \"data/processed\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Diretório \\'{output_dir}\\' criado.\")\n",
        "\n",
        "print(\"\\n--- Carregando o dataset processado de listings ---\")\n",
        "# Usar o arquivo listings_processed.csv fornecido pelo usuário\n",
        "df = pd.read_csv(\"https://github.com/RaphaelRAY/airbnb-rating-ml/raw/refs/heads/main/data/processed/listings_processed.csv\")\n",
        "print(f\"Dataset carregado. Shape inicial: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c69344",
      "metadata": {
        "id": "87c69344"
      },
      "source": [
        "## 2. Módulo `geo_features.py`\n",
        "\n",
        "As funções para baixar POIs, calcular distâncias (Haversine) e adicionar features geográficas foram encapsuladas no módulo `src/airbnb_rating/utils/geo_features.py` para melhor organização e reusabilidade. Este módulo inclui otimizações como o uso de índices espaciais para acelerar os cálculos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7f8740f8",
      "metadata": {
        "id": "7f8740f8"
      },
      "outputs": [],
      "source": [
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point, Polygon\n",
        "import os\n",
        "\n",
        "EARTH_RADIUS_KM = 6371\n",
        "\n",
        "def get_pois(city: str, geojson_path: str = None):\n",
        "    tags = {\n",
        "        \"natural\": \"beach\",\n",
        "        \"aeroway\": \"aerodrome\",\n",
        "        \"tourism\": True,\n",
        "        \"amenity\": [\"restaurant\", \"bar\", \"cafe\"],\n",
        "        \"leisure\": [\"park\"]\n",
        "    }\n",
        "    print(f\"Baixando POIs para {city} do OpenStreetMap...\")\n",
        "    pois = ox.features_from_place(city, tags)\n",
        "    return pois.to_crs(\"EPSG:4326\")\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return EARTH_RADIUS_KM * c\n",
        "\n",
        "def add_geo_features(df, city=\"Rio de Janeiro, Brazil\", geojson_path: str = None):\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df, geometry=gpd.points_from_xy(df[\"longitude\"], df[\"latitude\"]), crs=\"EPSG:4326\"\n",
        "    )\n",
        "    pois = get_pois(city, geojson_path)\n",
        "    beaches = pois[pois[\"natural\"] == \"beach\"]\n",
        "    airports = pois[pois[\"aeroway\"] == \"aerodrome\"]\n",
        "    tourism = pois[pois[\"tourism\"].notna()]\n",
        "    restaurants = pois[pois[\"amenity\"].isin([\"restaurant\", \"bar\", \"cafe\"]) if \"amenity\" in pois.columns else False]\n",
        "    parks = pois[pois[\"leisure\"] == \"park\"]\n",
        "\n",
        "    beaches_sindex = beaches.sindex\n",
        "    airports_sindex = airports.sindex\n",
        "    tourism_sindex = tourism.sindex\n",
        "    restaurants_sindex = restaurants.sindex\n",
        "    parks_sindex = parks.sindex\n",
        "\n",
        "    def get_poi_coords(geom):\n",
        "        if geom is None or not geom.is_valid:\n",
        "            return np.nan, np.nan\n",
        "        if geom.geom_type == 'Point':\n",
        "            return geom.y, geom.x\n",
        "        elif geom.geom_type == 'Polygon':\n",
        "            return geom.centroid.y, geom.centroid.x\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    def min_dist_optimized(point_geom, targets_gdf, targets_sindex):\n",
        "        if targets_gdf.empty:\n",
        "            return np.nan\n",
        "        possible_matches_indices = list(targets_sindex.intersection(point_geom.bounds))\n",
        "        if not possible_matches_indices:\n",
        "            return np.nan\n",
        "        min_d = np.inf\n",
        "        for idx in possible_matches_indices:\n",
        "            target_geom = targets_gdf.iloc[idx].geometry\n",
        "            target_lat, target_lon = get_poi_coords(target_geom)\n",
        "            if not np.isnan(target_lat):\n",
        "                dist = haversine(point_geom.y, point_geom.x, target_lat, target_lon)\n",
        "                if dist < min_d:\n",
        "                    min_d = dist\n",
        "        return min_d if min_d != np.inf else np.nan\n",
        "\n",
        "    print(\"Calculando distância para praias...\")\n",
        "    gdf[\"dist_beach_km\"] = gdf.geometry.apply(lambda p: min_dist_optimized(p, beaches, beaches_sindex))\n",
        "    print(\"Calculando distância para aeroportos...\")\n",
        "    gdf[\"dist_airport_km\"] = gdf.geometry.apply(lambda p: min_dist_optimized(p, airports, airports_sindex))\n",
        "    print(\"Calculando distância para pontos turísticos...\")\n",
        "    gdf[\"dist_touristic_km\"] = gdf.geometry.apply(lambda p: min_dist_optimized(p, tourism, tourism_sindex))\n",
        "\n",
        "    def count_nearby_optimized(point_geom, targets_gdf, targets_sindex, radius_km=1):\n",
        "        if targets_gdf.empty:\n",
        "            return 0\n",
        "        count = 0\n",
        "        radius_deg = radius_km / 111.139\n",
        "        buffered_point = point_geom.buffer(radius_deg)\n",
        "        possible_matches_indices = list(targets_sindex.intersection(buffered_point.bounds))\n",
        "\n",
        "        for idx in possible_matches_indices:\n",
        "            target_geom = targets_gdf.iloc[idx].geometry\n",
        "            target_lat, target_lon = get_poi_coords(target_geom)\n",
        "            if not np.isnan(target_lat):\n",
        "                if haversine(point_geom.y, point_geom.x, target_lat, target_lon) <= radius_km:\n",
        "                    count += 1\n",
        "        return count\n",
        "\n",
        "    print(\"Contando restaurantes próximos...\")\n",
        "    gdf[\"n_restaurants_1km\"] = gdf.geometry.apply(lambda p: count_nearby_optimized(p, restaurants, restaurants_sindex, radius_km=1))\n",
        "    print(\"Contando parques próximos...\")\n",
        "    gdf[\"n_parks_2km\"] = gdf.geometry.apply(lambda p: count_nearby_optimized(p, parks, parks_sindex, radius_km=2))\n",
        "\n",
        "    gdf = pd.DataFrame(gdf.drop(columns=\"geometry\"))\n",
        "    return gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e68112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12e68112",
        "outputId": "19a2cae5-5f58-43eb-cd3d-e4fee57d2cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Adicionando features geográficas automáticas ---\n",
            "Baixando POIs para Rio de Janeiro, Brazil do OpenStreetMap...\n",
            "Calculando distância para praias...\n",
            "Calculando distância para aeroportos...\n",
            "Calculando distância para pontos turísticos...\n",
            "Contando restaurantes próximos...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Adicionando features geográficas automáticas ---\")\n",
        "df_enriched = add_geo_features(df, city=\"Rio de Janeiro, Brazil\") # Usar\n",
        "print(f\"Dataset enriquecido. Novo shape: {df_enriched.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101813af",
      "metadata": {
        "id": "101813af"
      },
      "source": [
        "## 4. Salvando o Dataset Enriquecido\n",
        "\n",
        "O dataset resultante, contendo as novas features geográficas, é salvo em um novo arquivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3deac0",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "2a3deac0"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Salvando o dataset enriquecido ---\")\n",
        "df_enriched.to_csv(os.path.join(output_dir, \"airbnb_rio_geo_sample.csv\"), index=False) # Salvar amostra\n",
        "print(\"✅ Dataset enriquecido (amostra) salvo em data/processed/airbnb_rio_geo_sample.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb21eea7",
      "metadata": {
        "id": "bb21eea7"
      },
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}